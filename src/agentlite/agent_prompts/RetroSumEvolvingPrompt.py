from typing import List

from agentlite.agent_prompts.prompt_utils import (
    DEFAULT_PROMPT,
    PROMPT_TOKENS,
    task_chain_format,
)
from agentlite.commons import AgentAct, TaskPackage
from agentlite.agent_prompts.BasePrompt import BasePromptGen, PromptGen


EXTRACT_PROMPT = """
You are an expert in clinical reasoning and medical data analysis. You will be provided with a complete post-hoc analysis packages of a clinical reasoning task performed by an AI agent.

Your inputs include:
1.  **Query**: The original clinical question or task.
2.  **Complete Raw Trajectory**: The exhaustive, detailed log of every action taken and every raw observation received (e.g., full EHR tables, detailed reports) during the task.
3.  **Summarized Trajectory**: The sequence of high-level state summaries generated by the agent at each step, representing its compressed understanding of the situation at that moment.
4.  **Prediction Result & Ground Truth**: What the agent concluded versus what the actual correct answer was (indicating success or failure).

## Guidelines
Your task is to act as a **hindsight auditor**. You need to extract useful insights in the format of memory items by conducting a "gap analysis" among the provided inputs.
The goal is to identify critical reasoning patterns or information extraction strategies that led to success, or conversely, whose absence led to failure. These insights must be helpful and generalizable for improving future clinical summarization and reasoning tasks.

## Important notes
- **Hindsight Gap Analysis (Crucial):** Before summarizing, you must think critically with the benefit of knowing the Ground Truth. Compare the `Complete Raw Trajectory` against the `Summarized Trajectory`. Ask yourself:
    - If successful: What critical piece of raw data did the summary capture perfectly that connected the dots?
    - If failed: What critical piece of raw evidence (e.g., a subtle trend in labs over time, a specific medication in history) existed in the `Raw Trajectory` but was lost, diluted, or misinterpreted in the `Summarized Trajectory`, leading to the wrong prediction?
- **Focus on Correlation and Prioritization:** Focus on extracting insights about how to better correlate multiple, disparate data sources into a holistic picture, and how to prioritize subtle but clinically significant signals over noise during summarization.
- **Generalizable Principles:** Do not mention specific patient IDs, exact dates, specific hospital names, or exact string contents. Focus on abstract, generalizable clinical reasoning principles (e.g., instead of "Don't miss gentamicin," use "Always explicitly track nephrotoxic agent exposure history when new acute kidney injury markers appear").
- **Implicit Strategies:** Do not summarize strategies that are already obvious or mentioned in basic instructions; focus on the nuanced, implicit reasoning strategies revealed by this specific case audit.
- You can extract at most {max_items} memory items.
- You must not repeat similar or overlapping items.

## Output Format
Your output must strictly follow the Markdown format shown below. Ensure ALL fields (Title, Description, Content) are provided.

Required Format:
```
# Memory Item i
## Title <short title, max 15 words>
## Description <one sentence summary of the memory item>
## Content <1-3 sentences describing the insights learned to successfully accomplishing the task>
```

# Query:
{query}

# Complete Raw Trajectory: 
{raw_trajectory}

# Summarized Trajectory: 
{summarized_trajectory}

# Prediction Result: 
{prediction_result}

# Ground Truth: 
{ground_truth}
"""

REASONING_EXTRACT_PROMPT = """
You are an expert in clinical reasoning auditor. You will be provided with a complete post-hoc analysis package of a clinical reasoning task performed by an AI Actor agent.

Your inputs include:
1.  **User Query**: The original clinical question or task.
2.  **Prediction Result & Ground Truth**: What the Actor ultimately concluded versus the correct answer.
4.  **Complete Raw Trajectory / Actions Taken**: The exact actions the Actor took based on the summaries.

## Guidelines
Your task is to analyze the **reasoning quality** of the Actor agent. You need to extract useful insights in the format of memory items that focus on improving future clinical decision-making processes. The goal is to identify where the Actor's logic was flawed, overly cautious, too aggressive.

## Important notes
- **Focus on the Actor's Decisions:** Focus on: Given the information *present* at step T, did the Actor make the most logical action?
- **Analyze Reasoning Gaps:**
    - If failed: Did the Actor jump to a conclusion not supported by the retrieved information? Did it ignore conflicting evidence presented in the EHR records? Did it fail to order a necessary confirmatory test suggested by the recprds ambiguity?
    - If successful: What robust reasoning strategy did the Actor use to navigate uncertainty or complex data presented in the summaries?
- **Generalizable Reasoning Principles:** Insights should be about *how to think* clinically (e.g., differential diagnosis strategies, handling conflicting data, recognizing urgency), not about specific medical facts.
    - Do not summarize strategies that are already mentioned in the raw instructions; focus on the implicit reasoning strategies.
    - You can extract at most {max_items} memory items.
    - You must not repeat similar or overlapping items.

## Output Format
Your output must strictly follow the Markdown format shown below. Ensure ALL fields (Title, Description, Content) are provided.

Required Format:
```
# Memory Item i
## Title <short title, max 15 words>
## Description <one sentence summary of the memory item>
## Content <1-3 sentences describing the insights learned to successfully accomplishing the task>
```

# Query:
{query}

# Complete Trajectory: 
{raw_trajectory}

# Prediction Result: 
{prediction_result}

# Ground Truth: 
{ground_truth}
"""

SUMMARY_EXTRACT_PROMPT = """
You are an expert medical data summarization auditor. You will be provided with a complete post-hoc analysis package of a clinical reasoning task.

Your inputs include:
1.  **User Query**: The original clinical question or task.
2.  **Prediction Result & Ground Truth**: Knowing the final outcome is crucial for Hindsight bias analysis.
3.  **Complete Raw Trajectory**: The exhaustive, detailed truth (e.g., full EHR tables).
4.  **Summarized Trajectory**: The compressed version generated by the Summarizer.

## Guidelines
Your task is to conduct a **hindsight gap analysis** between the raw data and the generated summaries. You need to extract insights to improve how future Summarizers extract and compress clinical information.

## Important notes
- **Hindsight Gap Analysis (Crucial):** You must use the `Ground Truth` to identify what was truly important in the `Raw Trajectory`. Then, check if that important information was captured accurately in the `Summarized Trajectory`.
- **Focus on Information Loss/Distortion:**
    - **What was lost?** Identify critical raw data points (e.g., a subtle lab trend, a specific timing of medication) that were essential for the correct diagnosis but were omitted or overly generalized in the summary.
    - **Why it matters?** Explain how omitting this specific type of raw data leads to downstream reasoning errors.
- **Generalizable Summarization Principles:** Insights should be rules for *how to summarize* better (e.g., "Always preserve exact values for abnormal vitals instead of just stating 'abnormal'", "Explicitly link temporal relationships between medication administration and subsequent lab changes").
- You can extract at most {max_items} memory items.
- You must not repeat similar or overlapping items.

## Output Format
Your output must strictly follow the Markdown format shown below. Ensure ALL fields (Title, Description, Content) are provided.

Required Format:
```
# Memory Item i
## Title <short title, max 15 words>
## Description <one sentence summary of the memory item>
## Content <1-3 sentences describing the insights learned to successfully accomplishing the task>
```

# Query:
{query}

# Complete Trajectory: 
{raw_trajectory}

# Summarized Trajectory: 
{summarized_trajectory}

# Prediction Result: 
{prediction_result}

# Ground Truth: 
{ground_truth}
"""

class RetroSumEvolvingPrompt(PromptGen):
    """
    Prompt Generator for Reasoning Bank Memory Extraction.
    
    Generates prompts for extracting memory items from agent trajectories.
    Supports both success and failure trajectories, as well as self-contrast extraction.
    Adapted for Medical/Clinical scenarios.
    """
    
    def __init__(self, max_items: int = 3):
        """
        Args:
            max_items: Maximum number of memory items to extract per trajectory
        """
        super().__init__()
        self.prompt_type = "ReasoningBankPrompt"
        self.max_items = max_items
    
    def extract_reasoning_prompt(
        self,
        query: str,
        trajectory: str,
        ground_truth: str = None,
        model_output: str = None
    ) -> str:
        """
        Build the success extraction prompt from Figure 8 (Appendix A.1).
        
        Extracts generalizable strategies that contributed to success in clinical tasks.
        
        Args:
            query: Task query
            trajectory: Execution trace
            final_state: Final state (optional, not used in current template)
            model_output: Final output (optional, not used in current template)
        
        Returns:
            str: Complete success extraction prompt
        """
        
        return REASONING_EXTRACT_PROMPT.format(
            max_items=self.max_items,
            query=query,
            raw_trajectory=trajectory,
            prediction_result=model_output,
            ground_truth=ground_truth
        )


    def extract_summary_prompt(
        self,
        query: str,
        trajectory: str,
        summarized_trajectory: str,
        ground_truth: str = None,
        model_output: str = None
    ) -> str:
        """
        Build the success extraction prompt from Figure 8 (Appendix A.1).
        
        Extracts generalizable strategies that contributed to success in clinical tasks.
        
        Args:
            query: Task query
            trajectory: Execution trace
            final_state: Final state (optional, not used in current template)
            model_output: Final output (optional, not used in current template)
        
        Returns:
            str: Complete success extraction prompt
        """
        
        return SUMMARY_EXTRACT_PROMPT.format(
            max_items=self.max_items,
            query=query,
            raw_trajectory=trajectory,
            summarized_trajectory=summarized_trajectory,
            prediction_result=model_output,
            ground_truth=ground_truth
        )